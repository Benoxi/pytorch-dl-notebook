{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "train = datasets.MNIST(\"\", train=True, download=True, \n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "test = datasets.MNIST(\"\", train=False , download=True, \n",
    "                       transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for the general NN\n",
    "import torch.nn as nn\n",
    "# this is for specific functionality we are probably going to use\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        # leaving out the super will trigger error !!!\n",
    "        super().__init__()\n",
    "        # 28*28 - flatened picture size for the input\n",
    "        # 64 - the chosen output (could be any number really)\n",
    "        self.fc1 = nn.Linear((28*28), 64)\n",
    "        # for each next fc, the input must be the same as the last output\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        # the last one is going to have ouput 10, because we are guessing number from 0-9\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "        \n",
    "    # we define our network as feed forward!    \n",
    "    def forward(self, x):\n",
    "        # relu() - rectify lienar - activation function, decides wether the neuron is fired\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        # because the relu() runs on the output layer we do not want to run it on the\n",
    "        # last layer\n",
    "        x = self.fc4(x)\n",
    "        # no explanation for dim=1, just always use it\n",
    "        return F.log_softmax(x, dim=1)\n",
    "        \n",
    "        \n",
    "net = Net()\n",
    "# we can look at our NN, because there is an inbuilt function for print\n",
    "print(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4074, -2.3045, -2.2683, -2.4728, -2.2513, -2.4098, -2.2769, -2.1411,\n",
       "         -2.2396, -2.2966]], grad_fn=<LogSoftmaxBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.rand((28,28))\n",
    "# it is very important to format things EXACTLY like these libraries want them!\n",
    "# -1 - specefies that the input will be of an unknown shape\n",
    "X = X.view(-1, 28*28)\n",
    "output = net(X)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0119, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0020, grad_fn=<NllLossBackward>)\n",
      "tensor(0.0214, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# net.parameters() - contains all the variables of the net that we can change/adjust\n",
    "# lr - learning rate - this corresponds to the way we decide if some output is correct, \n",
    "# where we can use a mathematical formula to check how much off we are and correct our\n",
    "# weight in such a way that it's going to be correct. But the problem with correcting each\n",
    "# perfectly is that we lose the overall (general) solution to the problem we are solving\n",
    "# and this is called overfitting. So the learning rate is in place here to tell our NN\n",
    "# by how much it should correct itself, which directly corresponds to how fast it learns.\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# A whole pass through our data is called an EPOCH\n",
    "EPOCHS = 3\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for data in trainset:\n",
    "        # data is a batch of featuresets and labels\n",
    "        X, y = data\n",
    "        # printing the image \n",
    "        #print(X[0])\n",
    "        # printing the corresponding number\n",
    "        #print(y[0])\n",
    "        #break\n",
    "        # Everytime befor you pass data trough your NN\n",
    "        net.zero_grad()\n",
    "        # We batch our data because: \n",
    "        # 1.) It decreases training time (it's faster to train in baches)\n",
    "        # 2.) Between 32-128 of batch sizze helps generalizing\n",
    "        output = net(X.view(-1, 28*28))\n",
    "        # now we calculate how wrong are we\n",
    "        # nll_loss - if our data is a scalar\n",
    "        # mse_loss??? - if our data is a one hot vector [0, 1, 0, 0, 0]\n",
    "        loss = F.nll_loss(output, y)\n",
    "        # we backpropagate our loss\n",
    "        loss.backward()\n",
    "        # adjusts the weights for us\n",
    "        optimizer.step()\n",
    "    print(loss)\n",
    "    # what we actually want to see at this point is accuarcy.\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuarcy:  0.982\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in trainset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1, 784))\n",
    "        for idx, i in enumerate(output):\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "            \n",
    "print(\"Accuarcy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "predict_num = 3\n",
    "plt.imshow(X[predict_num].view(28,28))\n",
    "plt.show()\n",
    "print(torch.argmax(net(X[predict_num].view(-1, 784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
