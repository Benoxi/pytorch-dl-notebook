{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCOLUTIONAR NN\n",
    "\n",
    "The difference between **NN** and **CNN** is that, the CNN uses convolution to locate/discern features in an image. This is with multiple convolutional layers, which enable it to condense its data, for example an image. \n",
    "\n",
    "**Convolution** is done by selecting a smaller piece of the image, and *evaluate* it with a certain function (in this case **max pooling**) to determinate the next neuron in the layer. Then that value is relayed forward in to its neuron which reproduces the process a few more times until each piece, which is usually described as a **tensor**, is very simple. The goal of this proccess is for the neural network to be able to recognize something we would call \"features\" on the image. This proccess gives in conjuction with a lot of training is what is usually refered to as **Deep Learning**. \n",
    "So in *summary* CNNs drastically simplify the image and look for features in it and then try to learn what each of the features indicates. \n",
    "\n",
    "**Simple:** Reduces your image to simple building blocks and then finds patterns of these blocks given how many layers you have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data tricks ## \n",
    "\n",
    "Important note to make here is that for image classification many tricks can be used to make our dataset more rounded and higher the accuarcy for generalization. These tricks involve: croping images, resizing them and adding white spaces or even rotating them and using the modified versions as new images which can increase the number of our training samples by 4x (4 ways of rotating an image) or more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "24946\n"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# This data set is big so we don't want to rebuild it unless we change something.\n",
    "REBUILD_DATA = False\n",
    "\n",
    "# We generally don't need a class for this, but in our case (image processing) there are quite a few steps\n",
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50 # 50x50 pixels\n",
    "    CATS = \"Kaggle/PetImages/Cat\"\n",
    "    DOGS = \"Kaggle/PetImages/Dog\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "    # A important fact to mention is the importance of a balanced ammount of data for each class we are trying\n",
    "    # to disscerne. Therefore we will create counters here for each class and make sure there isn't an unbalance.\n",
    "    # Id there is an unbalance we will correct it.\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "    \n",
    "    def make_training_data(self):\n",
    "        # iterate trough our dictionary of classes\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            # iterate trough images in directory\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                try: \n",
    "                    # We use the os.path.join functrion to add a label (0 or 1) to each image\n",
    "                    path = os.path.join(label, f)\n",
    "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # converting to GRAYSCALE is not a necessity\n",
    "                    img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                    self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])\n",
    "\n",
    "                    if label == self.CATS:\n",
    "                        self.catcount += 1\n",
    "                    elif label == self.DOGS:\n",
    "                        self.dogcount += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # For some images there is an exception, maybe it's because they are corrupted or \n",
    "                    # maybe it's the resize...\n",
    "                    pass\n",
    "                    #print(str(e))\n",
    "\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print(\"Cats:\", self.catcount)\n",
    "        print(\"Dogs:\", self.dogcount)\n",
    "\n",
    "# If we want to rebuild everything (takes long time)\n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()\n",
    "    \n",
    "# We extract the training data so we don't have to create it again, for speeds sake\n",
    "# There is an issue with the pickle function.\n",
    "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
    "print(len(training_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our Neural Network ##\n",
    "\n",
    "In the next cell we build the convolutional network for this we have to import PyTorch-es libraries. We need the general `torch` library for tensors, the NN module, `torch.nn`, for convolutional functionality and we specifically save the functional part of the NN module, `torch.nn.functional`, in to F so we can access it through there.\n",
    "\n",
    "We start by defining a `Net` function, which will work as a constructor for our NN. We defien a initialization class `__init__(self)` which inherits it's parent init class form the `nn.Module`.\n",
    "Let's start the init by defining 3 convolutional layers (`conv1, conv2, conv3`), for which we use `nn.Conv2d` - \n",
    "We define the 2d convolutional function with 3 parameters `in_channels, out_channels, kernel_size`, where:\n",
    "- `in_channels`: number of channels in the input image\n",
    "- `out_channels`: number of channels produced by the convolution\n",
    "- `kernel_size`: size of the convolving kernel - int(5) = 5x5; tuple(5, 3) = 5x3 kernel\n",
    "\n",
    "** 2D convolution example: **\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1800/1*7S266Kq-UCExS25iX_I_AQ.png\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use a **max pooling** function, which is a *sample-based discretizaion process*, whose objective is to down-sample an input (in our case an image), which reduces its dimensionality by making assumptions about the features contained in the sub-regions of the sample being pooled.\n",
    "\n",
    "** Max pooling example: **\n",
    "\n",
    "<img src=\"https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max pool function which we are going to use is `nn.MaxPool2d`, which takes in:\n",
    "- `kernel_size` the size of the window to take the max over\n",
    "\n",
    "With this we define 3 different pools for each piece of the convolutional layers (`conv1, conv2, conv3`) for later use. In our case we are going to run our results through a 2x2 window (just like the example shows above). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next and last in line is an **linear transformation**. In PyTorch we have a predifined method that applies a linear transform, to the incomming data, in the shape of: \n",
    "\n",
    "$$ y = xA^{T} + b $$\n",
    "\n",
    "We apply the `torch.nn.Linear` function to our convolutional and pool output, but we have to determine the size of that output first. To do that we flatten foward feed the NN with a random example and print the results shape `print(x.shape)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to foward feed the `Net` with an example we have to first define the **foward feeding** function.\n",
    "\n",
    "So we create a function `foward` that takes in `self` and a parameter of `x` which represents our data. Inside this foward function we take our parameter **x** and we run it through our first convolutional layer, next we apply the rectified linear unit function to our layer with `torch.nn.functional.relu`, which returns a **tensor** that we lastly pass to our `torch.nn.MaxPool2d` function which we defined in our `__init__` class as `pool1, pool2` and `pool3`.\n",
    "\n",
    "After our input parameter **x** through all 3 of our layers we flatten the output `flatten(start_dim)`. The first time we run this function we output the shape of the result after all the layers, so we know what to input our `torch.nn.Linear` function above needs. In our case the output was 512.\n",
    "\n",
    "## Graph of the ReLU function: ## \n",
    "\n",
    "<img src=\"https://pytorch.org/docs/stable/_images/ReLU.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last 2 steps of the foward feeding function are to run our parameter through both `torch.nn.Linear` functions for the first we again use a `torch.nn.functional.relu` activation function so we get a linear spread in the result. We do not do use the same actiavtion function on the last layer, we rather use a one dimensional softmax function, the `torch.nn.functional.softmax`, before we return our output. The **softmax** function is defined as: \n",
    "\n",
    "$$ Softmax(x_{i}) = \\frac{exp(x_{i})}{\\sum_{j} exp(x_{i})} $$\n",
    "\n",
    "In our case it will be applied to all slices along our first dimeansion and that will rescale our values to between [0, 1] and so they together sum to 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Finished running\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d((2, 2))\n",
    "        self.pool2 = nn.MaxPool2d((2, 2))\n",
    "        self.pool3 = nn.MaxPool2d((2, 2))\n",
    "        \n",
    "        self.fc1 = nn.Linear(512, 512) # we got the first 512 value from our x.shape below when we ran a test fit.\n",
    "        self.fc2 = nn.Linear(512, 2) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = x.flatten(start_dim=1) # flattening out\n",
    "        #print(x.shape) # We print the shape for fc1 Linear\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        \n",
    "net = Net()\n",
    "#net.forward(torch.randn(1, 1, 50, 50)) # passing random sample data, to determine size of the fc1 layer input\n",
    "print(\"Finished running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "2494\n"
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50)\n",
    "X = X/255.0\n",
    "y = torch.Tensor([i[1] for i in training_data])\n",
    "\n",
    "VAL_PCT = 0.1\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "print(val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "22452\n2494\n"
    }
   ],
   "source": [
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]\n",
    "\n",
    "print(len(train_X))\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 225/225 [01:26<00:00,  2.59it/s]\ntensor(0.2171, grad_fn=<MseLossBackward>)\n"
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)):\n",
    "       #print(i, i+BATCH_SIZE)\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE]\n",
    "        \n",
    "        net.zero_grad()\n",
    "        outputs = net(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 2494/2494 [00:13<00:00, 182.10it/s]\nAccuarcy:0.626\n"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_X))):\n",
    "        real_class = torch.argmax(test_y[i])\n",
    "        net_out = net(test_X[i].view(-1, 1, 50, 50))[0]\n",
    "        predicted_class = torch.argmax(net_out)\n",
    "        if predicted_class == real_class:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "print(\"Accuarcy:\", round(correct/total,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}