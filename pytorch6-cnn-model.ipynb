{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONVOLUTIONAR NN\n",
    "\n",
    "The difference between **NN** and **CNN** is that, the CNN uses convolution to locate/discern features in an image. This is with multiple convolutional layers, which enable it to condense its data, for example an image. \n",
    "\n",
    "**Convolution** is done by selecting a smaller piece of the image, and *evaluate* it with a certain function (in this case **max pooling**) to determinate the next neuron in the layer. Then that value is relayed forward in to its neuron which reproduces the process a few more times until each piece, which is usually described as a **tensor**, is very simple. The goal of this proccess is for the neural network to be able to recognize something we would call \"features\" on the image. This proccess gives in conjuction with a lot of training is what is usually refered to as **Deep Learning**. \n",
    "So in *summary* CNNs drastically simplify the image and look for features in it and then try to learn what each of the features indicates. \n",
    "\n",
    "**Simple:** Reduces your image to simple building blocks and then finds patterns of these blocks given how many layers you have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training data tricks ## \n",
    "\n",
    "Important note to make here is that for image classification many tricks can be used to make our dataset more rounded and higher the accuarcy for generalization. These tricks involve: croping images, resizing them and adding white spaces or even rotating them and using the modified versions as new images which can increase the number of our training samples by 4x (4 ways of rotating an image) or more..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "24946\n"
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# This data set is big so we don't want to rebuild it unless we change something.\n",
    "REBUILD_DATA = False\n",
    "\n",
    "# We generally don't need a class for this, but in our case (image processing) there are quite a few steps\n",
    "class DogsVSCats():\n",
    "    IMG_SIZE = 50 # 50x50 pixels\n",
    "    CATS = \"Kaggle/PetImages/Cat\"\n",
    "    DOGS = \"Kaggle/PetImages/Dog\"\n",
    "    LABELS = {CATS: 0, DOGS: 1}\n",
    "    training_data = []\n",
    "    # A important fact to mention is the importance of a balanced ammount of data for each class we are trying\n",
    "    # to disscerne. Therefore we will create counters here for each class and make sure there isn't an unbalance.\n",
    "    # Id there is an unbalance we will correct it.\n",
    "    catcount = 0\n",
    "    dogcount = 0\n",
    "    \n",
    "    def make_training_data(self):\n",
    "        # iterate trough our dictionary of classes\n",
    "        for label in self.LABELS:\n",
    "            print(label)\n",
    "            # iterate trough images in directory\n",
    "            for f in tqdm(os.listdir(label)):\n",
    "                try: \n",
    "                    # We use the os.path.join functrion to add a label (0 or 1) to each image\n",
    "                    path = os.path.join(label, f)\n",
    "                    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # converting to GRAYSCALE is not a necessity\n",
    "                    img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))\n",
    "                    self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])\n",
    "\n",
    "                    if label == self.CATS:\n",
    "                        self.catcount += 1\n",
    "                    elif label == self.DOGS:\n",
    "                        self.dogcount += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    # For some images there is an exception, maybe it's because they are corrupted or \n",
    "                    # maybe it's the resize...\n",
    "                    pass\n",
    "                    #print(str(e))\n",
    "\n",
    "        np.random.shuffle(self.training_data)\n",
    "        np.save(\"training_data.npy\", self.training_data)\n",
    "        print(\"Cats:\", self.catcount)\n",
    "        print(\"Dogs:\", self.dogcount)\n",
    "\n",
    "# If we want to rebuild everything (takes long time)\n",
    "if REBUILD_DATA:\n",
    "    dogsvcats = DogsVSCats()\n",
    "    dogsvcats.make_training_data()\n",
    "    \n",
    "# We extract the training data so we don't have to create it again, for speeds sake\n",
    "# There is an issue with the pickle function.\n",
    "training_data = np.load(\"training_data.npy\", allow_pickle=True)\n",
    "print(len(training_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our Neural Network ##\n",
    "\n",
    "In the next cell we build the convolutional network for this we have to import PyTorch-es libraries. We need the general `torch` library for tensors, the NN module, `torch.nn`, for convolutional functionality and we specifically save the functional part of the NN module, `torch.nn.functional`, in to F so we can access it through there.\n",
    "\n",
    "We start by defining a `Net` function, which will work as a constructor for our NN. We defien a initialization class `__init__(self)` which inherits it's parent init class form the `nn.Module`.\n",
    "Let's start the init by defining 3 convolutional layers (`conv1, conv2, conv3`), for which we use `nn.Conv2d` - \n",
    "We define the 2d convolutional function with 3 parameters `in_channels, out_channels, kernel_size`, where:\n",
    "- `in_channels`: number of channels in the input image\n",
    "- `out_channels`: number of channels produced by the convolution\n",
    "- `kernel_size`: size of the convolving kernel - int(5) = 5x5; tuple(5, 3) = 5x3 kernel\n",
    "\n",
    "** 2D convolution example: **\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1800/1*7S266Kq-UCExS25iX_I_AQ.png\"> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we use a **max pooling** function, which is a *sample-based discretizaion process*, whose objective is to down-sample an input (in our case an image), which reduces its dimensionality by making assumptions about the features contained in the sub-regions of the sample being pooled.\n",
    "\n",
    "** Max pooling example: **\n",
    "\n",
    "<img src=\"https://computersciencewiki.org/images/8/8a/MaxpoolSample2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The max pool function which we are going to use is `nn.MaxPool2d`, which takes in:\n",
    "- `kernel_size` the size of the window to take the max over\n",
    "\n",
    "With this we define 3 different pools for each piece of the convolutional layers (`conv1, conv2, conv3`) for later use. In our case we are going to run our results through a 2x2 window (just like the example shows above). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next and last in line is an **linear transformation**. In PyTorch we have a predifined method that applies a linear transform, to the incomming data, in the shape of: \n",
    "\n",
    "$$ y = xA^{T} + b $$\n",
    "\n",
    "We apply the `torch.nn.Linear` function to our convolutional and pool output, but we have to determine the size of that output first. To do that we flatten foward feed the NN with a random example and print the results shape `print(x.shape)`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to foward feed the `Net` with an example we have to first define the **foward feeding** function.\n",
    "\n",
    "So we create a function `foward` that takes in `self` and a parameter of `x` which represents our data. Inside this foward function we take our parameter **x** and we run it through our first convolutional layer, next we apply the rectified linear unit function to our layer with `torch.nn.functional.relu`, which returns a **tensor** that we lastly pass to our `torch.nn.MaxPool2d` function which we defined in our `__init__` class as `pool1, pool2` and `pool3`.\n",
    "\n",
    "After our input parameter **x** through all 3 of our layers we flatten the output `flatten(start_dim)`. The first time we run this function we output the shape of the result after all the layers, so we know what to input our `torch.nn.Linear` function above needs. In our case the output was 512.\n",
    "\n",
    "## Graph of the ReLU function: ## \n",
    "\n",
    "<img src=\"https://pytorch.org/docs/stable/_images/ReLU.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last 2 steps of the foward feeding function are to run our parameter through both `torch.nn.Linear` functions for the first we again use a `torch.nn.functional.relu` activation function so we get a linear spread in the result. We do not do use the same actiavtion function on the last layer, we rather use a one dimensional softmax function, the `torch.nn.functional.softmax`, before we return our output. The **softmax** function is defined as: \n",
    "\n",
    "$$ Softmax(x_{i}) = \\frac{exp(x_{i})}{\\sum_{j} exp(x_{i})} $$\n",
    "\n",
    "In our case it will be applied to all slices along our first dimeansion and that will rescale our values to between $ [0, 1] $ and so they together sum to 1.\n",
    "\n",
    "So for our example say we train the net and put a picture of a cat in. The net must output 2 probability values that together make a sum of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "To get a preview of our NN we can simply print(net) and see how it is constructed: \n\nNet(\n  (conv1): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1))\n  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1))\n  (conv3): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1))\n  (pool1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (pool2): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (pool3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n  (fc1): Linear(in_features=512, out_features=512, bias=True)\n  (fc2): Linear(in_features=512, out_features=2, bias=True)\n)\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 5)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d((2, 2))\n",
    "        self.pool2 = nn.MaxPool2d((2, 2))\n",
    "        self.pool3 = nn.MaxPool2d((2, 2))\n",
    "        \n",
    "        self.fc1 = nn.Linear(512, 512) # we got the first 512 value from our x.shape below when we ran a test fit.\n",
    "        self.fc2 = nn.Linear(512, 2) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = x.flatten(start_dim=1) # flattening out\n",
    "        #print(x.shape) # We print the shape for fc1 Linear\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return F.softmax(x, dim=1)\n",
    "        \n",
    "net = Net()\n",
    "#net.forward(torch.randn(1, 1, 50, 50)) # passing random sample data, to determine size of the fc1 layer input\n",
    "print(\"To get a preview of our NN we can simply print(net) and see how it is constructed: \\n\")\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for our Net ##\n",
    "\n",
    "### Evaluating data ###\n",
    "\n",
    "Now that we have built our **neural network** we can start to train it. \n",
    "\n",
    "For this we need a **loss metric** and an **optimizer**. The loss metric tells us \"how far off\" the expected value we are and the optimizer reduces that training error, by adjusting out model parameters, like weights, and tries to reduce the loss metric to a number as low as possible, ** BUT NOT 0, BECAUSE THEN WE HAVE OVERFITTED OUR MODEL TO OUR TRAINING DATA AND WILL NOT GET A GOOD GENERAL RESULT**\n",
    "\n",
    "There are many optimizers built in to PyTorch. In this example we use **Adam** `torch.optim.Adam`. This is the go-to optimizer usually. **Adam** takes in:\n",
    "\n",
    "- `params` which are our NN paramteres\n",
    "- `lr` which is the rate at which it adjusting the parameters or *learning rate*\n",
    "\n",
    "We are going to pass in a learning rate of $0.001$ as a balanced number so our optimizer does not get stuck by making too big improvements or making no improvements at all.\n",
    "\n",
    "<img src=\"https://pythonprogramming.net/static/images/machine-learning/learning-rate-too-high-too-low.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to the function for our loss metric. In our example we expect a result which is commonly described as **\"one_hot\"** vector, which means that in array of sorts we expect one of our values to be **\"fired\"**. This simply means that we have an array of values for which we expect only one number to be 1, all other values 0.\n",
    "\n",
    "$$ \\text{for a result of 3 out of 10 the one_hot vector would be}: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0] $$\n",
    "\n",
    "Because our example is a sort of \"yes and no\" classifier we tend to use **MSE** `torch.nn.MSELoss`, mean squared error, for these loss metric, because they yeald the best results. \n",
    "\n",
    "If we had more of a **scalar classification** we could use **cross entropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating data ###\n",
    "\n",
    "Now we want to iterate over our data, but we need to also do this in batches. We also want to separate out our data into training and testing groups. \n",
    "Also along with the separation of our data into **featuresets (X)** and **labels (y)**, because our NN expects a specific input shape (50x50), we must shape each image to fit the input of the NN. We can reshape our images using the `torch.Tensor.view` function which takes in a parameter of `shape(torch.Size or python:int...)`.\n",
    "\n",
    "So under each training_data element in the first row i[0] we find our *\"featureset\"*, which we can imagine as our **inputs** and under i[1] we find our *\"labels\"* which we can imagine as **expected outputs**.\n",
    "\n",
    "We store the data as `torch.Tensor`, which is the data type our NN uses.\n",
    "\n",
    "After the separation we normalize each image by divding our **X** dataset with 255 (all image data is GRAYSCALED from 1 to 255), putting all our input values between 0 and 1. **(NORMALIZATION)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor([i[0] for i in training_data]).view(-1, 50, 50)\n",
    "X = X/255.0\n",
    "y = torch.Tensor([i[1] for i in training_data])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because after training we also have to test our data, we need test samples. These test samples are usually some percentage of the original dataset in our case we will use 10% for testing. This means 90% of all our data is used for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Expected test sample size: 2494\nTraining dataset: 22452\nTesting dataset: 2494\n"
    }
   ],
   "source": [
    "VAL_PCT = 0.1\n",
    "val_size = int(len(X)*VAL_PCT)\n",
    "print(f\"Expected test sample size: {val_size}\")\n",
    "\n",
    "\n",
    "train_X = X[:-val_size]\n",
    "train_y = y[:-val_size]\n",
    "\n",
    "test_X = X[-val_size:]\n",
    "test_y = y[-val_size:]\n",
    "\n",
    "print(f\"Training dataset: {len(train_X)}\")\n",
    "print(f\"Testing dataset: {len(test_X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing our Net ##\n",
    "\n",
    "### Training ###\n",
    "\n",
    "We split our data in to **BATCH_SIZE**-es, which defines how many subjects at a time we are going to itterate through.\n",
    "First we split the data in to two batches each containing our data split in to pieces of size equal to our BATCH_SIZE. We do 2 splits, one for the **inputs (train_X)** and one for the **exepcted outputs (train_y)**.\n",
    "\n",
    "Then before we start training we have to *zero the gradient*, which for our `torch.nn.Module` Net we can use the built in function `torch.nn.Module.zero_grad` for that.\n",
    "We could also call the `torch.nn.Module.zero_grad` function on the specific optimizer if we should wish to. That would be usefull if we had more then one optimizer in our NN and wanted to zero_grad them seperately.\n",
    "\n",
    "We start the training by calling our Nets `__init__` function with our batch as an the input.\n",
    "The next sensible step is to calculate our loss by calling to out `loss_function`. We compute the gradients of the current tensors in out batch through the `backward()` function, and perform a optimization step in our optimizer (`Adam`) with `step()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 225/225 [01:27<00:00,  2.58it/s]\nEpoch: 0, loss: 0.20131699740886688\nAfter 1 epochs, the final loss is: 0.20131699740886688\n"
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for i in tqdm(range(0, len(train_X), BATCH_SIZE)): # from 0, to the len of x, stepping BATCH_SIZE at a time. \n",
    "       #print(i, i+BATCH_SIZE)\n",
    "        batch_X = train_X[i:i+BATCH_SIZE].view(-1, 1, 50, 50)\n",
    "        batch_y = train_y[i:i+BATCH_SIZE]\n",
    "        \n",
    "        net.zero_grad()\n",
    "\n",
    "        outputs = net(batch_X)\n",
    "        loss = loss_function(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "    print(f\"Epoch: {epoch}, loss: {loss}\")\n",
    "\n",
    "print(f\"After {EPOCHS} epochs, the final loss is: {loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing ###\n",
    "\n",
    "We iterate through all results, we get the indexes of the answers with `torch.argmax`, which returns the index of the element with the highest value.\n",
    "\n",
    "We run our test data (`test_X`) through our net, and we get the predicted classifications of our net by again using `torch.argmax` on our testing output results.\n",
    "\n",
    "Then we increment the correct results and total results, so we can finally coompare them to each other!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "100%|██████████| 2494/2494 [00:13<00:00, 184.22it/s]\nAccuarcy: 0.639\n"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in tqdm(range(len(test_X))): # TQDM is used for the progress bar\n",
    "        correct_class = torch.argmax(test_y[i]) # we get the correct classification using argmax\n",
    "        net_output = net(test_X[i].view(-1, 1, 50, 50))[0] \n",
    "        predicted_class = torch.argmax(net_output)\n",
    "        if predicted_class == correct_class:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "        \n",
    "print(f\"Accuarcy: {round(correct/total,3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}